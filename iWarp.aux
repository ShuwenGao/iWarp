\relax 
\citation{nvidia2009nvidia}
\citation{lindholm2008nvidia}
\citation{nvidia2008programming}
\citation{munshi2009opencl}
\citation{nvidia2008programming}
\citation{nvidia2008programming}
\citation{lindholm2008nvidia}
\citation{lindholm2008nvidia}
\citation{sdk2010v2}
\citation{jia2014mrpb}
\citation{grauer2012auto}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Baseline GPGPU Architecture}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Cache Contention}{1}}
\newlabel{sec:contention}{{2.2}{1}}
\citation{rogers2012cache}
\citation{jog2013owl}
\citation{jia2014mrpb}
\citation{rogers2012cache}
\citation{bakhoda2009analyzing}
\citation{grauer2012auto}
\citation{jia2014mrpb}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Baseline GPU architecture. While each streaming multiprocessor has its own warp scheduler and L1 cache as on-chip private resources, L2 caches are connected to the interconnection network as memory partitions which are shared by the multiple streaming multiprocessors. }}}{2}}
\newlabel{fig:gpu}{{1}{2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces atax\_kernel1}}{2}}
\newlabel{algo:atax}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Misses per thousand instructions (MPKI) of L1D cache with different cache size. Cache misses are categorized into intra-warp contention, inter-warp contention and other (pure misses). For heavy memory intensive benchmarks, the misses mainly comes from intra-warp contention and changes very little with enlarged cache size. For moderate memory intensive benchmarks, the misses mainly comes from inter-warp contention and drops significantly with larger cache size.}}}{2}}
\newlabel{fig:mpki}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  { Misses per thousand instructions (MPKI) of L2 cache across memory intensive benchmarks with different L1D cache size. With a significantly larger size compared to L1D cache, the misses in L2 cache mainly comes from inter-warp contention. }}}{2}}
\newlabel{fig:l2_mpki}{{3}{2}}
\newlabel{fig:swl_l1}{{4(a)}{2}}
\newlabel{sub@fig:swl_l1}{{(a)}{2}}
\newlabel{fig:swl_l2}{{4(b)}{2}}
\newlabel{sub@fig:swl_l2}{{(b)}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {(a) L1D miss rate with SWL scheduler. With different number of active warps, the L1D miss rates are similar, because the cache size too small to accommodate the data for even a single warp. (b) L2D miss rate with SWL scheduler. The lowest miss rate is achieved when the number of active warps is less than the maximum except for GESUMMV, whose input size is smaller than other three benchmarks.}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{2}}
\citation{che2009rodinia}
\citation{he2008mars}
\citation{nvidia2009nvidia}
\citation{wong2010demystifying}
\citation{rogers2012cache}
\citation{narasiman2011improving}
\citation{jog2013orchestrated}
\citation{jog2013owl}
\citation{rogers2012cache}
\citation{rogers2012cache}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Warp Scheduling}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Interference-Aware Scheduling}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview of iWarp}{3}}
\citation{jia2014mrpb}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Scheduling Strategy}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}L1-level}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Illustration of inter-warp contention in L1D cache. Data D0 and D4 that are rereferenced by warp W0 and W3, respectively, have inter-warp contention with each other.}}}{4}}
\newlabel{fig:l1_contention}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Illustration of iWarp working scheme on L1-level using the example in Figure 5\hbox {}. The first time warp W3 requests data D4, D0 in cache set0 will be replaced. Then when W0 requests D0 again, data reuse of D4 is detected, so as the contention between W0 and W3. iWarp stalls loading W3, and thus further data reuse of D0 from W0 will hit on L1D cache.}}}{4}}
\newlabel{fig:iWarp_l1}{{6}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}L2-level}{4}}
\newlabel{fig:l2_1}{{7(a)}{5}}
\newlabel{sub@fig:l2_1}{{(a)}{5}}
\newlabel{fig:l2_2}{{7(b)}{5}}
\newlabel{sub@fig:l2_2}{{(b)}{5}}
\newlabel{fig:l2_3}{{7(c)}{5}}
\newlabel{sub@fig:l2_3}{{(c)}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {A representative example of the cache contention problem and our iWarp scheduling strategies. (a) An ideal case where despite severe intra-warp contentions in L1D cache, there is no inter-warp contention in the L2 cache. Every data missed in the L1D cache can always hit in the L2 cache. (b) Newly requested data for warp1 in core0 (C0W1) occupies the cache blocks in L2, which introduces inter-warp contention in L2 cache. This contention causes L2 misses for other cores as their data has been replaced and can eventually be detected in core0. (c) Once the cache interference is detected, iWarp stalls the warp1 in core0, and the corresponding data will be stalled loading to L2 cache, which will reduce the L2 misses. }}}{5}}
\newlabel{fig:l2}{{7}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Without L2-level interference. }}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {With L2-level interference. }}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {L2-level interference eliminated. }}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Scheduler Implementation}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cache Structure Modification}{5}}
\newlabel{sec:arch}{{4.1}{5}}
\citation{grauer2012auto}
\citation{grauer2012auto}
\citation{grauer2012auto}
\citation{grauer2012auto}
\citation{che2009rodinia}
\citation{he2008mars}
\citation{che2009rodinia}
\bibstyle{acm}
\bibdata{iWarp}
\bibcite{bakhoda2009analyzing}{{1}{}{{}}{{}}}
\bibcite{che2009rodinia}{{2}{}{{}}{{}}}
\bibcite{grauer2012auto}{{3}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Modified cache structure for our proposed iWarp scheme. A warp ID (WID) is added to each L1D cache line and a victim tag array (VTA) is introduced for each warp. The warp contention information is detected in VTA upon cache miss, and is fed back to the warp scheduler. }}}{6}}
\newlabel{fig:vta}{{8}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {iWarp strategy details. (a) When a cache line is evicted from the L1D, its tag is written into the VTA portion that corresponds to the warp reserving it (marked using the WID). (b) Upon a cache miss, the requested data's tag is probed in the requesting warp's corresponding VTA. If the tag is found, a hit signal is generated. }}}{6}}
\newlabel{fig:vta_ex}{{9}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {GPGPU-Sim configuration.}}}{6}}
\newlabel{tab:config}{{1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {GPGPU benchmarks.}}}{6}}
\newlabel{tab:benchmark}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Cache Interference Aware Scheduling}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Methodology}{6}}
\newlabel{sec:method}{{5.1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experimental Results}{6}}
\newlabel{sec:result}{{5.2}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Performance Analysis}{6}}
\newlabel{sec:analy}{{5.2.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix Title}{6}}
\newlabel{fig:16k_ipc}{{10(a)}{7}}
\newlabel{sub@fig:16k_ipc}{{(a)}{7}}
\newlabel{fig:48k_ipc}{{10(b)}{7}}
\newlabel{sub@fig:48k_ipc}{{(b)}{7}}
\newlabel{fig:64k_ipc}{{10(c)}{7}}
\newlabel{sub@fig:64k_ipc}{{(c)}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Overall performance improvement of CCWS and iWarp with different size of L1D cache, normalized to GTO. With a small 16KB L1D cache, CCWS and iWarp improve the performance of heavy memory intensive benchmarks of 5.4\% and 18.3\% over GTO, respectively. With a larger 48KB L1D cache size, CCWS and iWarp improve the performance of heavy memory intensive benchmarks of 8.3\% and 17.8\% over GTO, respectively. As the cache size is enlarged to 64KB, the improvement of CCWS decreases to 1.9\%, while iWarp sill achieves 15.8\% improvement over GTO. As the L1D cache size becomes larger, cache interference of moderate cache sensitive benchmarks decreases significantly, and thus CCWS and iWrap tend to have similar performance with GTO. }}}{7}}
\newlabel{fig:ipc}{{10}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {16KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {48KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {64KB. }}}{7}}
\newlabel{fig:16k_l1_miss_rate}{{11(a)}{7}}
\newlabel{sub@fig:16k_l1_miss_rate}{{(a)}{7}}
\newlabel{fig:48k_l1_miss_rate}{{11(b)}{7}}
\newlabel{sub@fig:48k_l1_miss_rate}{{(b)}{7}}
\newlabel{fig:64k_l1_miss_rate}{{11(c)}{7}}
\newlabel{sub@fig:64k_l1_miss_rate}{{(c)}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {L1 miss rate of three schedulers. For heavy memory intensive benchmarks, the L1 miss rates with different warp schedulers are similar due to the huge intra-warp contention. For moderate memory intensive benchmarks, CCWS and iWrap reduces the L1 miss rate with small 16KB L1D cache, and have similar L1 miss rate with GTO with larger L1D cache. }}}{7}}
\newlabel{fig:l1_miss_rate}{{11}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {16KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {48KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {64KB. }}}{7}}
\newlabel{fig:16k_12_miss_rate}{{12(a)}{7}}
\newlabel{sub@fig:16k_12_miss_rate}{{(a)}{7}}
\newlabel{fig:48k_l2_miss_rate}{{12(b)}{7}}
\newlabel{sub@fig:48k_l2_miss_rate}{{(b)}{7}}
\newlabel{fig:64k_l2_miss_rate}{{12(c)}{7}}
\newlabel{sub@fig:64k_l2_miss_rate}{{(c)}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {L2 miss rate of three schedulers. For heavy memory intensive benchmarks, iWarp achieves the lowest L2 miss rate among the three schedulers with different size of L1D cache. }}}{7}}
\newlabel{fig:l2_miss_rate}{{12}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {16KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {48KB. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {64KB. }}}{7}}
\bibcite{he2008mars}{{4}{}{{}}{{}}}
\bibcite{jia2014mrpb}{{5}{}{{}}{{}}}
\bibcite{jog2013orchestrated}{{6}{}{{}}{{}}}
\bibcite{jog2013owl}{{7}{}{{}}{{}}}
\bibcite{lindholm2008nvidia}{{8}{}{{}}{{}}}
\bibcite{munshi2009opencl}{{9}{}{{}}{{}}}
\bibcite{narasiman2011improving}{{10}{}{{}}{{}}}
\bibcite{nvidia2008programming}{{11}{}{{}}{{}}}
\bibcite{nvidia2009nvidia}{{12}{}{{}}{{}}}
\bibcite{rogers2012cache}{{13}{}{{}}{{}}}
\bibcite{sdk2010v2}{{14}{}{{}}{{}}}
\bibcite{wong2010demystifying}{{15}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{fig:16k_avg_mf}{{13(a)}{8}}
\newlabel{sub@fig:16k_avg_mf}{{(a)}{8}}
\newlabel{fig:48k_avg_mf}{{13(b)}{8}}
\newlabel{sub@fig:48k_avg_mf}{{(b)}{8}}
\newlabel{fig:64k_avg_mf}{{13(c)}{8}}
\newlabel{sub@fig:64k_avg_mf}{{(c)}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \textbf  {Average memory fetch latency of three schedulers, normalized to GTO. For heavy memory intensive benchmarks, iWarp achieves the shortest average memory fetch latency among the three schedulers with different size of L1D cache. }}}{8}}
\newlabel{fig:mf}{{13}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {16KB. }}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {48KB. }}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {64KB. }}}{8}}
\newlabel{sigplanconf@finalpage}{{A}{8}}
